{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoAmRych4zjz"
      },
      "source": [
        "# RBE/CS549 Fall 2022: Computer Vision\n",
        "## Homework 0: Alohomora\n",
        "\n",
        "Author(s): \n",
        "Prof. Nitin J. Sanket (nsanket@wpi.edu), Lening Li (lli4@wpi.edu), Gejji, Vaishnavi Vivek (vgejji@wpi.edu)\n",
        "\n",
        "Robotics Engineering Department,\n",
        "\n",
        "Worcester Polytechnic Institute\n",
        "\n",
        "Code adapted from CMSC733 at the University of Maryland, College Park."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OTbKmZc84z9"
      },
      "source": [
        "\n",
        "## Phase 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tShNtcK9syo_"
      },
      "source": [
        "### Get the BSDS500 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6poCzkgco7sv"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/leelening/rbe549/main/hw0/BSDS500.tar.xz\n",
        "!tar -xvf BSDS500.tar.xz\n",
        "!mv BSDS500/ /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FH307bN0MDt"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/leelening/rbe549/main/hw0/TxtFiles.tar.xz\n",
        "!tar -xvf TxtFiles.tar.xz\n",
        "!mv TxtFiles/ /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lak3Alk44zj1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plot\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imutils2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN-AX2a04zj2"
      },
      "source": [
        "1. Generate Difference of Gaussian Filter Bank: (DoG)\n",
        "2. Display all the filters in this filter bank and save image as DoG.png,\n",
        "3. use command \"cv2.imwrite(...)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9sMEggi4zj3"
      },
      "source": [
        "\n",
        "1. Generate Leung-Malik Filter Bank: (LM)\n",
        "2. Display all the filters in this filter bank and save image as LM.png,\n",
        "3. use command \"cv2.imwrite(...)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_ihdTUc4zj3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Load Images\n",
        "\"\"\"\n",
        "def load_imgs(folder_name):\n",
        "\t#Storing all the images in the variable imgs\n",
        "\timgs=[]\n",
        "\tfor filename in os.listdir(folder_name):\n",
        "\t\timg = cv2.imread(os.path.join(folder_name,filename))\n",
        "\t\tif img is not None:\n",
        "\t\t\timgs.append(img)\n",
        "\t\telse:\n",
        "\t\t\tprint(\"No image found in this folder!!\")\n",
        "\treturn imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Show Images\n",
        "\"\"\"\n",
        "def show_img(imgs):\n",
        "\n",
        "\tfor img in imgs:\n",
        "\t\tcv2.namedWindow(\"Show Image\")\n",
        "\t\tcv2.imshow(\"Input\", img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Print Results of a filter Bank in Matplot\n",
        "\"\"\"\n",
        "def print_filterbank_results_matplot(Filter,file_name, cols):\n",
        "\ti =0\n",
        "\t\t\t\n",
        "\trows = math.ceil(len(Filter )/cols)\t\n",
        "\tplot.subplots(rows, cols, figsize=(15,15))\n",
        "\tfor index in range(len(Filter )):\n",
        "\t\tplot.subplot(rows, cols, index+1)\n",
        "\t\tplot.axis('off')\n",
        "\t\tplot.imshow(Filter [index], cmap='gray')\n",
        "\t\n",
        "\tplot.savefig(file_name)\n",
        "\tplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Chi Square distance\n",
        "\"\"\"\n",
        "def chisquareDistance(input, bins, filter_bank):\n",
        "\n",
        "\tchi_sq_dis = []\n",
        "\tN = len(filter_bank)\n",
        "\ti = 0\n",
        "\twhile i < N:\n",
        "\t\tleft_mask = filter_bank[i]\n",
        "\t\tright_mask = filter_bank[i+1]\t\t\n",
        "\t\ttmp = np.zeros(input.shape)\n",
        "\t\tcsd = np.zeros(input.shape)\n",
        "\t\tmin_bin = np.min(input)\n",
        "\t\n",
        "\n",
        "\t\tfor bin in range(bins):\n",
        "\t\t\ttmp[input == bin+min_bin] = 1\n",
        "\t\t\tg_i = cv2.filter2D(tmp,-1,left_mask)\n",
        "\t\t\th_i = cv2.filter2D(tmp,-1,right_mask)\n",
        "\t\t\tterm1 = (g_i - h_i)**2\n",
        "\t\t\tterm2 = 1/(g_i + h_i + np.exp(-7))\n",
        "\t\t\tcsd += term1*term2\n",
        "\n",
        "\t\tcsd /= 2\n",
        "\t\tchi_sq_dis.append(csd)\n",
        "\t\ti = i+2\n",
        "    \t\n",
        "\n",
        "\treturn chi_sq_dis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Generate Gaussian Filter:\t\n",
        "\"\"\"\n",
        "def gaussian(sigma,kernel_size):\n",
        "\tsigma_x, sigma_y = sigma\n",
        "\tGauss = np.zeros([kernel_size, kernel_size])\n",
        "\t# x = np.linspace(0,kernel_size)\n",
        "\t# y = np.linspace(0,kernel_size)\n",
        "\tif(kernel_size/2):\n",
        "\t\tindex = kernel_size/2\n",
        "\telse:\n",
        "\t\tindex = (kernel_size - 1)/2\n",
        "\tx,y= np.meshgrid(np.linspace(-index,index,kernel_size),np.linspace(-index,index,kernel_size))\n",
        "\tterm1 = 0.5/(np.pi*sigma_x*sigma_y)\n",
        "\t\n",
        "\tterm2 = np.exp(-((np.square(x)/(np.square(sigma_x))+(np.square(y)/(np.square(sigma_y))))))/2\n",
        "\tGauss = term1*term2\n",
        "\treturn Gauss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Generate Difference of Gaussian Filter Bank: (DoG)\n",
        "Display all the filters in this filter bank and save image as DoG.png,\n",
        "use command \"cv2.imwrite(...)\"\n",
        "\"\"\"\n",
        "def DOG_FilterBank(orientation_values,scale_values,kernel_size):\n",
        "\n",
        "\tDOG= []\n",
        "\t\"\"\"\n",
        "\tSobel Filter - Fixed \n",
        "\t\"\"\"\n",
        "\n",
        "\tSobel_x = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
        "\tSobel_y = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n",
        "\n",
        "\n",
        "\tfor scale in scale_values:\n",
        "\t\tsigma = [scale, scale]\n",
        "\t\tGauss = gaussian(sigma,kernel_size)\n",
        "\n",
        "\t\tDOG_X = cv2.filter2D(Gauss,-1,Sobel_x)\n",
        "\t\tDOG_Y = cv2.filter2D(Gauss,-1,Sobel_y)\n",
        "\t\tfor ori in range(orientation_values):\n",
        "\t\t\tcurr_orientation = ori *2 *np.pi /orientation_values\n",
        "\t\t\tDOG_Filter = (DOG_X * np.cos(curr_orientation)) +(DOG_Y *np.sin(curr_orientation))\n",
        "\t\t\tDOG.append(DOG_Filter)\n",
        "\t# np_array = np.array(DOG, dtype=np.int32)\n",
        "\t# DOG= np_array.astype(np.float32)\n",
        "\t# DOG.astype('float32') \n",
        "\t# print (DOG)\n",
        "\tfig, axs = plot.subplots(len(scale_values),orientation_values,figsize=(orientation_values,len(scale_values)))\n",
        "\tfor i in range(len(scale_values)):\n",
        "\t\tfor j in range(orientation_values):\n",
        "\t\t\t\t\n",
        "\t\t\t\taxs[i, j].imshow(DOG[i*orientation_values+j],cmap='gray')\n",
        "\t\t\t\taxs[i, j].axis('off')\n",
        "\n",
        "\t# plot.show()\n",
        "\t# plot.savefig(\"/home/uthira/usivaraman_hw0/Phase1/Results/DOG.png\")\n",
        "\tplot.close()\n",
        "\treturn DOG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Generate Leung-Malik Filter Bank: (LM)\n",
        "Display all the filters in this filter bank and save image as LM.png,\n",
        "use command \"cv2.imwrite(...)\"\n",
        "\"\"\"\n",
        "def LM_FilterBank(orientation_values,scale_values,kernel_size):\n",
        "\n",
        "\tLM =[]\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tDefining Scales :\n",
        "\tDerivate filter : 3\n",
        "\tLaplacian of Gaussian filter : 8 (sigma+sigma*3)\n",
        "\tGaussian : 4\n",
        "\t\"\"\"\n",
        "\tDerivatives_scale = scale_values[0:3]\n",
        "\tGaussinaFilter_scale = scale_values\n",
        "\tLOGFilter_scale =[]\n",
        "\tfor i in range(len(scale_values)):\n",
        "\t\tscale = scale_values[i]\n",
        "\t\tLOG_scale_value = scale + 3 *scale\n",
        "\t\tLOGFilter_scale.append(LOG_scale_value)\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tFirst and Second Derivatives of Gauss Filter\n",
        "\t\"\"\"\n",
        "\tFirstD =[]\n",
        "\tSecondD=[]\n",
        "\tfor scale in Derivatives_scale :\n",
        "\t\tsigma = [scale, scale]\n",
        "\n",
        "\t\t\n",
        "\t\tdel_x = np.array([[-1, 0, 1],[-2, 0, 2], [-1, 0, 1]])\n",
        "\t\tdel_y = np.array([[-1, -2, -1],[0, 0, 0], [1, 2, 1]])\n",
        "\t\tGauss = gaussian(sigma,kernel_size)\t\t\n",
        "\t\tFirstD_x = cv2.filter2D(Gauss,-1,del_x)\n",
        "\t\tFirstD_y = cv2.filter2D(Gauss,-1,del_y)\n",
        "\t\tSecondD_x = cv2.filter2D(FirstD_x,-1,del_x)\n",
        "\t\tSecondD_Y = cv2.filter2D(FirstD_y,-1,del_y)\n",
        "\t\tfor ori in range(orientation_values):\n",
        "\t\t\tcurr_orientation = ori *2 *np.pi /orientation_values\n",
        "\t\t\tFirstD_Filter = (FirstD_x* np.cos(curr_orientation)) +(FirstD_y *np.sin(curr_orientation))\n",
        "\t\t\tSecondtD_Filter = (SecondD_x* np.cos(curr_orientation)) +(SecondD_Y *np.sin(curr_orientation))\n",
        "\t\t\tFirstD.append(FirstD_Filter)\n",
        "\t\t\tSecondD.append(SecondtD_Filter)\n",
        "\n",
        "\t\"\"\"\n",
        "\tLaplacian of Gaussian Filter\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tLOG=[]\n",
        "\tif(kernel_size/2):\n",
        "\t\t\tindex = kernel_size/2\n",
        "\telse:\n",
        "\t\t\tindex = (kernel_size - 1)/2\n",
        "\tfor scale in LOGFilter_scale:\n",
        "\t\tsigma = [scale, scale]\n",
        "\t\tGauss = gaussian(sigma, kernel_size)\n",
        "\t\tLog_kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
        "\t\tLOG_Filter= cv2.filter2D(Gauss,-1,Log_kernel)\n",
        "\t\tLOG.append(LOG_Filter)\n",
        "\t\t# x,y= np.meshgrid(np.linspace(-index,index,kernel_size),np.linspace(-index,index,kernel_size))\n",
        "\t\t# term1 = -1/(np.pi*np.square(sigma[0])*np.square(sigma[1]))\n",
        "\t\t# term2 = (1-((np.square(x)/(np.square(sigma[0]))+(np.square(y)/(np.square(sigma[1]))))))\n",
        "\t\t# term3 = np.exp(-((np.square(x)/(np.square(sigma[0]))+(np.square(y)/(np.square(sigma[1]))))))/2\n",
        "\t\t# LOG_filter = term1*term2*term3\n",
        "\t\t# LOG.append(LOG_filter)\n",
        "\n",
        "\t\"\"\"\n",
        "\tGaussian Filter\n",
        "\t\"\"\"\n",
        "\tGaussian=[]\n",
        "\tfor scale in GaussinaFilter_scale:\n",
        "\t\tsigma = [scale, scale]\n",
        "\t\tGaussian.append(gaussian(sigma, kernel_size))\n",
        "\t\n",
        "\tLM = FirstD +SecondD + LOG + Gaussian\n",
        "\n",
        "\tfig, axs = plot.subplots(len(scale_values),orientation_values,figsize=(orientation_values,len(scale_values)))\n",
        "\tfor i in range(len(scale_values)):\n",
        "\t\tfor j in range(orientation_values):\n",
        "\t\t\t\t\n",
        "\t\t\t\taxs[i, j].imshow(LM[i*orientation_values+j],cmap='gray')\n",
        "\t\t\t\taxs[i, j].axis('off')\n",
        "\t# plot.show()\n",
        "\treturn LM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Generate Sine Wave:\t\n",
        "\"\"\"\n",
        "def sinewave(frequency,kernel_size,angle):\n",
        "\t\n",
        "\t\n",
        "\tindex = (kernel_size - 1)/2\n",
        "\n",
        "\tx, y = np.meshgrid(np.linspace(-index, index+1, kernel_size), np.linspace(-index, index+1, kernel_size))\n",
        "\tvalue= x * np.cos(angle) + y * np.sin(angle)\n",
        "\tsin2d = np.sin(value* 2 * np.pi * frequency/kernel_size)\n",
        "\n",
        "\treturn sin2d\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Generate Gabor Filter Bank: (Gabor)\n",
        "Display all the filters in this filter bank and save image as Gabor.png,\n",
        "use command \"cv2.imwrite(...)\"\n",
        "\"\"\"\n",
        "def Gabor_FilterBank(orientation_values,scale_values,frequency_values,kernel_size):\n",
        "\n",
        "\tGabor =[]\n",
        "\tfor scale in scale_values:\n",
        "\t\tsigma = [scale, scale]\n",
        "\t\tGauss = gaussian(sigma,kernel_size)\n",
        "\t\tfor angle in range(orientation_values):\n",
        "\t\t\tfor frequency in frequency_values:\n",
        "\t\t\t\tSinewaveFilter =sinewave(frequency,kernel_size,angle)\n",
        "\t\t\t\tGabor_Filter = Gauss*SinewaveFilter\n",
        "\t\t\t\tGabor.append(Gabor_Filter)\n",
        "\tfig, axs = plot.subplots(len(scale_values),orientation_values,figsize=(orientation_values,len(scale_values)))\n",
        "\tfor i in range(len(scale_values)):\n",
        "\t\tfor j in range(orientation_values):\n",
        "\t\t\t\t\n",
        "\t\t\t\taxs[i, j].imshow(Gabor[i*orientation_values+j],cmap='gray')\n",
        "\t\t\t\taxs[i, j].axis('off')\n",
        "\t# plot.show()\n",
        "\t# plot.savefig(\"/home/uthira/usivaraman_hw0/Phase1/Results/Gabor.png\")\n",
        "\tplot.close()\n",
        "\treturn Gabor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "Generate Half-disk masks\n",
        "Display all the Half-disk masks and save image as HDMasks.png,\n",
        "use command \"cv2.imwrite(...)\"\n",
        "\"\"\"\n",
        "def HalfDisk(radius, angle):\n",
        "\t# radius = 3\n",
        "\t# Half_disk_masks =np.ones((8,8))\n",
        "\t# y,x = np.ogrid[-3: 3+1, 0: 3+1]\n",
        "\t# Half_disk_masks = x**2+y**2 <= 3**2\n",
        "\t# Half_disk_masks = np.array(Half_disk_masks)\n",
        "\t# print(Half_disk_masks)\n",
        "\t# print_filterbank_results_matplot(Half_disk_masks,'/home/uthira/CV/Cvis_HW0/Phase1/Results/Filter/HalfDiskMasks.png', 8)\n",
        "\tsize = 2*radius + 1\n",
        "\tcentre = radius\n",
        "\thalf_disk = np.zeros([size, size])\n",
        "\tfor i in range(radius):\n",
        "\t\tfor j in range(size):\n",
        "\t\t\tdistance = np.square(i-centre) + np.square(j-centre)\n",
        "\t\t\tif distance <= np.square(radius):\n",
        "\t\t\t\thalf_disk[i,j] = 1\n",
        "    \n",
        "\t\n",
        "\thalf_disk = imutils.rotate(half_disk, angle)\n",
        "\thalf_disk[half_disk<=0.5] = 0\n",
        "\thalf_disk[half_disk>0.5] = 1\n",
        "\treturn half_disk\n",
        "def halfdiskFilters(radii, orientations):\n",
        "\tfilter_bank = []\n",
        "\tfor radius in radii:\n",
        "\t\tfilter_bank_pairs = []\n",
        "\t\ttemp = []\n",
        "\t\tfor orientation in range(orientations):\n",
        "\t\t\tangle = orientation * 360 / orientations\n",
        "\t\t\thalf_disk_filter = HalfDisk(radius, angle)\n",
        "\t\t\ttemp.append(half_disk_filter)\n",
        "\n",
        "        #to make pairs\n",
        "\t\ti = 0\n",
        "\t\twhile i < orientations/2:\n",
        "\t\t\tfilter_bank_pairs.append(temp[i])\n",
        "\t\t\tfilter_bank_pairs.append(temp[i+int((orientations)/2)])\n",
        "\t\t\ti = i+1\n",
        "\n",
        "\t\tfilter_bank+=filter_bank_pairs\n",
        "\t\n",
        "\t\n",
        "\treturn filter_bank\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def pblite_edges(T_g, B_g, C_g, Canny_edge, Sobel_edges, weights):\n",
        "\tCanny_edge = cv2.cvtColor(Canny_edge, cv2.COLOR_BGR2GRAY)\n",
        "\tSobel_edges = cv2.cvtColor(Sobel_edges, cv2.COLOR_BGR2GRAY)\n",
        "\tT1 = (T_g + B_g + C_g)/3\n",
        "\tw1 = weights[0]\n",
        "\tw2 = weights[1]\n",
        "\tT2 = (w1 * Canny_edge) + (w2 * Sobel_edges)\n",
        "\t# print(T1.shape)\n",
        "\t# print(T2.shape)\n",
        "\tpb_lite_output = np.multiply(T1, T2)\n",
        "\treturn pb_lite_output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Derivative of Gaussian Filter\"\"\"\t\n",
        "DOG_FB = DOG_FilterBank(18,[3,3],36)\t\t\n",
        "# print_filterbank_results_matplot(DOG_FB,'/home/uthira/CV/Cvis_HW0/Phase1/Results/Filter/DOG.png',8)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"LM Filter\"\"\"\t\n",
        "LM_FB_small = LM_FilterBank(6,[1,np.sqrt(2),2,2*np.sqrt(2)],49)\t\t\n",
        "LM_FB_large= LM_FilterBank(6,[np.sqrt(2),2,2*np.sqrt(2),4],49)\t\n",
        "# print_filterbank_results_matplot(LM_FB_small,'/home/uthira/CV/Cvis_HW0/Phase1/Results/Filter/LM_small.png',12)\n",
        "# print_filterbank_results_matplot(LM_FB_large,'/home/uthira/CV/Cvis_HW0/Phase1/Results/Filter/LM_large.png',12)\n",
        "LM_FB = LM_FB_small + LM_FB_large\n",
        "# print_filterbank_results_matplot(LM_FB,'/home/uthira/CV/Cvis_HW0/Phase1/Results/Filter/LM.png',12)\n",
        "\n",
        "fig, axs = plot.subplots(8,6,figsize=(6,8))\n",
        "for i in range(8):\n",
        "\tfor j in range(6):\n",
        "\t\t\t\n",
        "\t\t\taxs[i, j].imshow(LM_FB[i*6+j],cmap='gray')\n",
        "\t\t\taxs[i, j].axis('off')\n",
        "# plot.show()\n",
        "\n",
        "\n",
        "\"\"\"Gabor Filter\"\"\"\t\n",
        "Gabor_FB = Gabor_FilterBank(6,[20,45],[3,4,6],49)\t\t\n",
        "# print_filterbank_results_matplot(Gabor_FB,'/home/uthira/CV/Cvis_HW0/Phase1/Results/Filter/Gabor.png',8)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Total Filter Bank \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "textron_gradients = []\n",
        "brightness_gradients = []\n",
        "color_gradients = []\n",
        "half_disk_filter_bank = halfdiskFilters([2,5,10,20,30], 16)\n",
        "index =0\n",
        "\n",
        "images_folder = \"./content/data/BSDS500/Images/\"\n",
        "results_folder = \"./Results/\"\n",
        "\n",
        "image_files = os.listdir(images_folder)\n",
        "for img_name in image_files:\n",
        "\tprint(\"image name\",img_name)\n",
        "\timg_path = images_folder + img_name\n",
        "\timg = cv2.imread(img_path)\n",
        "\t# plot.imshow(img, cmap = \"gray\")\n",
        "\t# plot.show()\n",
        "\tprint(\"index:\",index)\n",
        "\timage_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\tfilterbank = DOG_FB + LM_FB + Gabor_FB\n",
        "\tfiltered_images =[]\n",
        "\tfor fb in filterbank:\n",
        "\t\tResults = cv2.filter2D(image_gray,-1, fb)\t\n",
        "\t\tfiltered_images.append(Results)\n",
        "\tfilename = results_folder+\"Filter/\"+\"Fbank_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(path , image_name), img)\n",
        "# cv2.waitKey(0)\n",
        "\t# print_filterbank_results_matplot(filtered_images,filename,8)\t\t\n",
        "\t# cv2.imshow(\"output\", Results)\n",
        "\t# cv2.waitKey()\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tGenerate Texton Map\n",
        "\tFilter image using oriented gaussian filter bank\n",
        "\t\"\"\"\n",
        "\tfiltered_images= np.array(filtered_images)\n",
        "\t# print(\"Shape of Filtered Images\")\n",
        "\t# print(filtered_images.shape)\n",
        "\t# print(\"Length of Filterbank\")\n",
        "\t# print(len(filterbank))\n",
        "\tf,x,y = filtered_images.shape\n",
        "\tinput_mat = filtered_images.reshape([f, x*y])\n",
        "\tinput_mat = input_mat.transpose()\n",
        "\t# print(\"Input to Kmeans clustering\")\n",
        "\t# print(input_mat)\n",
        "\t# print(input_mat.shape)\n",
        "\t\n",
        "\n",
        "\n",
        "\n",
        "\t\"\"\"\n",
        "\tGenerate texture ID's using K-means clustering\n",
        "\tDisplay texton map and save image as TextonMap_ImageName.png,\n",
        "\tuse command \"cv2.imwrite('...)\"\n",
        "\t\"\"\"\n",
        "\tprint(\"Textron Maps\")\n",
        "\tkmeans = KMeans(n_clusters=64, init='k-means++', max_iter=300, n_init=2, random_state=0)\n",
        "\tkmeans.fit(input_mat)\n",
        "\tlabels = kmeans.predict(input_mat)\n",
        "\ttexton_image = labels.reshape([x,y])\n",
        "\tprint(texton_image.shape)\n",
        "\timage_name =\"Texton_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(results_folder , image_name), T_g)\n",
        "\tplot.imsave(os.path.join(results_folder , image_name),  texton_image, cmap = None)\n",
        "\t# textron_maps.append(texton_image)\n",
        "\t\"\"\"\n",
        "\tGenerate Texton Gradient (Tg)\n",
        "\tPerform Chi-square calculation on Texton Map\n",
        "\tDisplay Tg and save image as Tg_ImageName.png,\n",
        "\tuse command \"cv2.imwrite(...)\"\n",
        "\t\"\"\"\n",
        "\tT_g = chisquareDistance(texton_image, 64, half_disk_filter_bank)\n",
        "\tT_g = np.array(T_g)\n",
        "\tT_g = np.mean(T_g, axis = 0)\n",
        "\t#plt.imshow(T_g)\n",
        "\t#plt.show()\t\n",
        "\ttextron_gradients.append(T_g)\n",
        "\t# plot.imshow(T_g, cmap=None)\n",
        "\t# plot.show()\t\n",
        "\t# plot.close()\n",
        "\t# T_g = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\timage_name =\"Tg_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(results_folder , image_name), T_g)\n",
        "\tplot.imsave(os.path.join(results_folder , image_name),  T_g, cmap = None)\n",
        "\n",
        "\t# plot.imshow(texton_image)\t\n",
        "\t# plot.show()\t\n",
        "\t# plot.close()\n",
        "\t# plot.imsave(os.path.join(\"/home/uthira/CV/Cvis_HW0/Phase1/Results/Textron_map/\", \"TextonMap_\"+str(index)) , texton_image)\n",
        "\t\n",
        "\n",
        "\t\"\"\"\n",
        "\tGenerate Brightness Map\n",
        "\tPerform brightness binning \n",
        "\t\"\"\"\n",
        "\tprint(\"generating brightness maps..\")\n",
        "\t\n",
        "\t# for i,image in enumerate(images):\n",
        "\timage_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\tx,y = image_gray.shape\n",
        "\tinput_mat = image_gray.reshape([x*y,1])\n",
        "\tkmeans = KMeans(n_clusters = 16, n_init = 4)\n",
        "\tkmeans.fit(input_mat)\n",
        "\tlabels = kmeans.predict(input_mat)\n",
        "\tbrightness_image = labels.reshape([x,y])\n",
        "\tprint(brightness_image.shape)\n",
        "\timage_name =\"Bright_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(results_folder , image_name), T_g)\n",
        "\tplot.imsave(os.path.join(results_folder , image_name),  brightness_image, cmap = None)\n",
        "\t\"\"\"\n",
        "\tGenerate Brightness Gradient (Bg)\n",
        "\tPerform Chi-square calculation on Brightness Map\n",
        "\tDisplay Bg and save image as Bg_ImageName.png,\n",
        "\tuse command \"cv2.imwrite(...)\"\n",
        "\t\"\"\"\n",
        "\t# brightness_maps.append(brightness_image)\n",
        "\tB_g = chisquareDistance(brightness_image, 16, half_disk_filter_bank)\n",
        "\tB_g = np.array(B_g)\n",
        "\tB_g = np.mean(B_g, axis = 0)\n",
        "\t#plt.imshow(B_g)\n",
        "\t#plt.show()\n",
        "\tbrightness_gradients.append(B_g)\n",
        "\timage_name =\"Bg_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(results_folder , image_name), B_g)\n",
        "\tplot.imsave(os.path.join(results_folder , image_name),  B_g, cmap = None)\n",
        "\t\t# plot.imshow(brightness_image)\n",
        "\t\t# plot.show()\n",
        "\t\t# plt.imsave(folder_name + \"results/Brightness_map/BrightnessMap_\" + file_names[i], brightness_image)\n",
        "\n",
        "\t\n",
        "\n",
        "\t\"\"\"\n",
        "\tGenerate Color Map\n",
        "\tPerform color binning or clustering\n",
        "\t\"\"\"\n",
        "\tprint(\"generating color maps..\")\n",
        "\t\n",
        "\t\n",
        "\tx,y,c = img.shape\n",
        "\tinput_mat = img.reshape([x*y,c])\n",
        "\n",
        "\tkmeans = KMeans(n_clusters =16, n_init = 4)\n",
        "\tkmeans.fit(input_mat)\n",
        "\tlabels = kmeans.predict(input_mat)\n",
        "\tcolor_image = labels.reshape([x,y])\n",
        "\timage_name =\"Color_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(results_folder , image_name), T_g)\n",
        "\tplot.imsave(os.path.join(results_folder , image_name),  color_image, cmap = None)\n",
        "\t# color_maps.append(color_image)\n",
        "\t\"\"\"\n",
        "\tGenerate Color Gradient (Cg)\n",
        "\tPerform Chi-square calculation on Color Map\n",
        "\tDisplay Cg and save image as Cg_ImageName.png,\n",
        "\tuse command \"cv2.imwrite(...)\"\n",
        "\t\"\"\"\n",
        "\tC_g = chisquareDistance(color_image,16, half_disk_filter_bank)\n",
        "\tC_g = np.array(C_g)\n",
        "\tC_g = np.mean(C_g, axis = 0)\n",
        "\t# print(color_image.shape)\n",
        "\t#plt.imshow(C_g)\n",
        "\t#plt.show()\n",
        "\tcolor_gradients.append(C_g)\n",
        "\timage_name =\"Cg_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(results_folder , image_name), C_g)\n",
        "\tplot.imsave(os.path.join(results_folder , image_name),  C_g, cmap = None)\n",
        "\t\t#plt.imshow(color_image)\n",
        "\t\t#plt.show()\t\t\t\n",
        "\t\t# plt.imsave(folder_name + \"results/Color_map/ColorMap_\"+ file_names[i], color_image)\n",
        "\t\"\"\"\n",
        "\tCombine responses to get pb-lite output\n",
        "\tDisplay PbLite and save image as PbLite_ImageName.png\n",
        "\tuse command \"cv2.imwrite(...)\"\n",
        "\t\"\"\"\n",
        "\tprint(\"generating pb lite output..\")\n",
        "\t# for i in range(len(images)):\t\n",
        "\tsobel_pb = cv2.imread(\"./content/data/BSDS500/SobelBaseline/\" + img_name)\n",
        "\tcanny_pb = cv2.imread(\"./content/data/BSDS500/SobelBaseline/\" + img_name)\n",
        "\tpb_edge = pblite_edges(T_g, B_g, C_g, canny_pb, sobel_pb, [0.5,0.5])\n",
        "\tprint(\"Final Output\")\n",
        "\t# plot.imshow(pb_edge, cmap = \"gray\")\n",
        "\tplot.show()\n",
        "\t# pb_edge =cv2.cvtColor(pb_edge, cv2.COLOR_BGR2GRAY)\n",
        "\timage_name =\"PbLite_\"+img_name\n",
        "\t# cv2.imwrite(os.path.join(results_folder , image_name), pb_edge)\n",
        "\tplot.imsave(os.path.join(results_folder , image_name), pb_edge, cmap = \"gray\")\n",
        "\t# /home/uthira/CV/Cvis_HW0/Phase1/Results/Pblite/Figure_1.png\n",
        "\t\n",
        "\tindex = index +1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2aeH7uq8qR7"
      },
      "source": [
        "## Phase 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4iWkcHsItB0"
      },
      "source": [
        "### Neural Network Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGCHa0pfIss-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "def loss_fn(out, labels):\n",
        "    ###############################################\n",
        "    # Fill your loss function of choice here!\n",
        "    ###############################################\n",
        "    LossFn = nn.CrossEntropyLoss()\n",
        "    loss = LossFn(out, labels)\n",
        "    return loss\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = loss_fn(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = loss_fn(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'loss': loss.detach(), 'acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'loss': epoch_loss.item(), 'acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], loss: {:.4f}, acc: {:.4f}\".format(epoch, result['loss'], result['acc']))\n",
        "\n",
        "\n",
        "##################################\n",
        "#Basic\n",
        "##################################  \n",
        "\n",
        "class CIFAR10Model(ImageClassificationBase):\n",
        "    def __init__(self, InputSize, OutputSize):\n",
        "    \n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "        InputSize - Size of the Input\n",
        "        OutputSize - Size of the Output\n",
        "        \"\"\"\n",
        "        #############################\n",
        "        # Fill your network initialization of choice here!\n",
        "            # Fill your network initialization of choice here!\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),nn.MaxPool2d(kernel_size = 10, stride = 10))   \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU())\n",
        "        self.fc1= nn.Sequential(\n",
        "            nn.Linear(512, OutputSize))\n",
        "\n",
        "    \n",
        "    #############################\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "      \n",
        "    def forward(self, xb):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        xb is a MiniBatch of the current image\n",
        "        Outputs:\n",
        "        out - output of the network\n",
        "        \"\"\"\n",
        "        #############################\n",
        "        # Fill your network structure of choice here!\n",
        "        #############################\n",
        "        out = self.layer1(xb)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        # out = self.layer4(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = F.softmax(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "##################################\n",
        "#ResNet 18\n",
        "##################################    \n",
        "\n",
        "class ResNet(ImageClassificationBase):\n",
        "    def __init__(self,OutputSize):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv_1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(64),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(64, 128, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(2))\n",
        "\n",
        "        self.res_1 = nn.Sequential(nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(128),\n",
        "                                nn.ReLU())\n",
        "\n",
        "        self.conv_2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(256),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(2),\n",
        "                                nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(512),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(2))\n",
        "\n",
        "        self.res_2 = nn.Sequential(nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(512),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "                                nn.BatchNorm2d(512),\n",
        "                                nn.ReLU())\n",
        "        \n",
        "        self.fc = nn.Sequential(  \n",
        "                                        nn.Linear(512, OutputSize))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv_1(xb)\n",
        "        # print(out.shape)\n",
        "        out = self.res_1(out) + out\n",
        "        # print(out.shape)\n",
        "        out = self.conv_2(out)\n",
        "        # print(out.shape)\n",
        "        out = self.res_2(out) + out\n",
        "        # print(out.shape)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "##################################\n",
        "#ResNet 34\n",
        "##################################        \n",
        "# class ResNet(ImageClassificationBase):\n",
        "    # def __init__(self, OutputSize):\n",
        "    #     super().__init__()\n",
        "    #     #34 layer res_net\n",
        "    #     self.conv_1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(64),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(64, 64, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(64),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(64, 128, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(128),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.MaxPool2d(2))\n",
        "\n",
        "    #     self.res_1 = nn.Sequential(nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(128),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(128),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(128),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(128),\n",
        "    #                             nn.ReLU())\n",
        "\n",
        "    #     self.conv_2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(256),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(256),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(256),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             # nn.MaxPool2d(2),\n",
        "    #                             nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(256),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(256),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(512),\n",
        "    #                             nn.ReLU())\n",
        "\n",
        "    #     self.res_2 = nn.Sequential(nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(512),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(512),\n",
        "    #                             nn.ReLU(),\n",
        "    #                             nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "    #                             nn.BatchNorm2d(512),\n",
        "    #                             nn.ReLU())\n",
        "    #     self.avgpool = nn.AvgPool2d(5)\n",
        "    #     self.fc= nn.Sequential(nn.Linear(512, OutputSize)) \n",
        "        \n",
        "    # def forward(self, xb):\n",
        "    #     out = self.conv_1(xb)\n",
        "    #     # print(out.shape)\n",
        "    #     out = self.res_1(out) + out\n",
        "    #     # print(out.shape)\n",
        "    #     out = self.conv_2(out)\n",
        "    #     # print(out.shape)\n",
        "    #     out = self.res_2(out) + out\n",
        "    #     out = self.avgpool(out)\n",
        "    #     # print(out.shape)\n",
        "    #     out = torch.flatten(out, 1)\n",
        "    #     # print(out.shape)\n",
        "    #     out = self.fc(out)\n",
        "    #     # print(out.shape)\n",
        "    #     return out\n",
        "\n",
        "##################################\n",
        "#DenseNet\n",
        "################################## \n",
        "class block(nn.Module):\n",
        "    def __init__(self, in_channels,growth_rate,bottleneck_width):\n",
        "        super().__init__()\n",
        "        # print(\"Inchannels in block :\",in_channels)\n",
        "        self.layers = nn.Sequential(\n",
        "                                    nn.BatchNorm2d(in_channels),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Conv2d(in_channels, bottleneck_width*growth_rate, kernel_size=1, padding=0),          #1x1 convolution\n",
        "                                    nn.BatchNorm2d(bottleneck_width*growth_rate),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Conv2d(bottleneck_width*growth_rate, growth_rate, kernel_size=3, padding=1))                    #3x3 convolution\n",
        "              \n",
        "\n",
        "    def forward(self, xb):\n",
        "        \n",
        "        out = self.layers(xb)        \n",
        "        out = torch.cat([xb, out], 1)            \n",
        "        return out\n",
        "\n",
        "\n",
        "class DenseNet(ImageClassificationBase):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        growth_rate = 6                                                                \n",
        "        num_layers= 6                                                           \n",
        "        num_features= 12\n",
        "        bottleneck_width = 4\n",
        "        self.conv1 = nn.Conv2d(3, 12, kernel_size = 1)  \n",
        "                      \n",
        "        self.dense1 = self.dense(num_features,growth_rate, num_layers,bottleneck_width)\n",
        "        num_features += num_layers * growth_rate  \n",
        "        # print(num_features)\n",
        "        self.trans1 = nn.Sequential(nn.BatchNorm2d(num_features),                    \n",
        "                                        nn.Conv2d(num_features, 48, kernel_size=1, padding=0),\n",
        "                                        nn.AvgPool2d(2))\n",
        "        num_features= 48\n",
        "        self.dense2 = self.dense(num_features, growth_rate, num_layers,bottleneck_width)\n",
        "        num_features += num_layers * growth_rate \n",
        "        print(num_features)\n",
        "        self.trans2 = nn.Sequential(nn.BatchNorm2d(num_features),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Conv2d(num_features, 96, kernel_size=1, padding=0)\n",
        "                                        )\n",
        "\n",
        "        num_features= 96\n",
        "        self.dense3 = self.dense(num_features,growth_rate, num_layers,bottleneck_width)\n",
        "        num_features += num_layers * growth_rate\n",
        "        print(num_features)\n",
        "        self.classifier = nn.Sequential(nn.BatchNorm2d(num_features),            \n",
        "                                        nn.AvgPool2d(5),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Linear(132, 10))\n",
        "\n",
        "    def dense(self, features, grate, num_layers,bottleneck_width):                            \n",
        "        layers = []\n",
        "        for i in range(num_layers):\n",
        "            layers.append(block(features, grate,bottleneck_width))\n",
        "            features += grate\n",
        "            # print(\"features :\",features)\n",
        "        # print(layers)\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        # print(out.shape)\n",
        "        out = self.dense1(out)\n",
        "        # print(out.shape)\n",
        "        out = self.trans1(out)\n",
        "        # print(out.shape)\n",
        "        out = self.dense2(out)\n",
        "        # print(out.shape)\n",
        "        out = self.trans2(out)\n",
        "        # print(out.shape)\n",
        "        out = self.dense3(out)\n",
        "        # out = torch.flatten(out, 1)\n",
        "        # print(out.shape)\n",
        "        out = self.classifier(out)\n",
        "        # print(out.shape)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "##################################\n",
        "#ResNeXT\n",
        "##################################\n",
        "\n",
        "class res_block(nn.Module):\n",
        "    def __init__(self, in_features, num_layers,inplanes, stride):\n",
        "        super().__init__()\n",
        "        features = num_layers*inplanes             \n",
        "        self.layers = nn.Sequential(nn.Conv2d(in_features, features, kernel_size = 1),\n",
        "                                    nn.BatchNorm2d(features),\n",
        "                                    nn.Conv2d(features, features, kernel_size = 3, stride = stride, padding = 1, groups = num_layers), #2 groups made(as C=2 in our case)\n",
        "                                    nn.BatchNorm2d(features),\n",
        "                                    nn.Conv2d(features, 2*features, kernel_size = 1),\n",
        "                                    nn.BatchNorm2d(2*features))\n",
        "        self.residual = nn.Sequential(nn.Conv2d(in_features, 2*features, kernel_size = 1, stride = stride),\n",
        "                                    nn.BatchNorm2d(2*features))\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        out = self.layers(xb)\n",
        "        out += self.residual(xb)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNeXt(ImageClassificationBase):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "       \n",
        "        self.num_layers = 2\n",
        "        self.in_features = 64\n",
        "        self.bottleneck_width = 2\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.block1 = self.block(self.in_channels, self.num_layers, self.in_features, 1)\n",
        "        self.in_channels = self.bottleneck_width*self.num_layers*self.in_features\n",
        "        self.in_features = self.in_features*2\n",
        "        self.block2 = self.block(self.in_channels, self.num_layers, self.in_features,2) \n",
        "        self.in_channels = self.bottleneck_width*self.num_layers*self.in_features\n",
        "        self.in_features = self.in_features*2          \n",
        "        self.block3 = self.block(self.in_channels, self.num_layers, self.in_features,2)\n",
        "        \n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        # self.batchnorm=nn.BatchNorm2d(1024)\n",
        "        self.fc = nn.Sequential(nn.Linear(1024,10))\n",
        "        # self.fc1 =nn.Sequential( nn.Linear(9126,10))                               \n",
        "\n",
        "\n",
        "\n",
        "    def block(self,in_,nlayers,inf, stride):\n",
        "        layers = []\n",
        "        layers.append(res_block(in_, nlayers, inf, stride))        \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self,xb):\n",
        "        out = self.conv1(xb)\n",
        "        # print(out.shape)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.block1(out)\n",
        "        # print(out.shape)\n",
        "        out = self.block2(out)\n",
        "        # print(out.shape)\n",
        "        out = self.block3(out)\n",
        "        out= self.avgpool(out)\n",
        "        # out= self.batchnorm(out)\n",
        "        out = torch.flatten(out, 1) \n",
        "        \n",
        "        # print(out.shape)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SPck2oRdL5j"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def tic():\n",
        "    \"\"\"\n",
        "    Function to start timer\n",
        "    Tries to mimic tic() toc() in MATLAB\n",
        "    \"\"\"\n",
        "    StartTime = time.time()\n",
        "    return StartTime\n",
        "\n",
        "def toc(StartTime):\n",
        "    \"\"\"\n",
        "    Function to stop timer\n",
        "    Tries to mimic tic() toc() in MATLAB\n",
        "    \"\"\"\n",
        "    return time.time() - StartTime\n",
        "\n",
        "def FindLatestModel(CheckPointPath):\n",
        "    \"\"\"\n",
        "    Finds Latest Model in CheckPointPath\n",
        "    Inputs:\n",
        "    CheckPointPath - Path where you have stored checkpoints\n",
        "    Outputs:\n",
        "    LatestFile - File Name of the latest checkpoint\n",
        "    \"\"\"\n",
        "    FileList = glob.glob(CheckPointPath + '*.ckpt.index') # * means all if need specific format then *.csv\n",
        "    LatestFile = max(FileList, key=os.path.getctime)\n",
        "    # Strip everything else except needed information\n",
        "    LatestFile = LatestFile.replace(CheckPointPath, '')\n",
        "    LatestFile = LatestFile.replace('.ckpt.index', '')\n",
        "    return LatestFile\n",
        "\n",
        "\n",
        "def convertToOneHot(vector, NumClasses):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    vector - vector of argmax indexes\n",
        "    NumClasses - Number of classes\n",
        "    \"\"\"\n",
        "    return np.equal.outer(vector, np.arange(NumClasses)).astype(np.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A04kYJ_rJxEP"
      },
      "source": [
        "### Train your neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hcGOFRE2JueB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as tf\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import skimage\n",
        "import PIL\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from skimage import data, exposure, img_as_float\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from torchvision.transforms import ToTensor\n",
        "import argparse\n",
        "import shutil\n",
        "import string\n",
        "from termcolor import colored, cprint\n",
        "import math as m\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Don't generate pyc codes\n",
        "sys.dont_write_bytecode = True\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "def SetupAll(CheckPointPath):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "    CheckPointPath - Path to save checkpoints/model\n",
        "    Outputs:\n",
        "    SaveCheckPoint - Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
        "    ImageSize - Size of the image\n",
        "    NumTrainSamples - length(Train)\n",
        "    TrainLabels - Labels corresponding to Train\n",
        "    NumClasses - Number of classes\n",
        "    \"\"\"\n",
        "    # Read and Setup Labels\n",
        "    LabelsPathTrain = '/content/data/TxtFiles/LabelsTrain.txt'\n",
        "    TrainLabels = ReadLabels(LabelsPathTrain)\n",
        "\n",
        "    # If CheckPointPath doesn't exist make the path\n",
        "    if(not (os.path.isdir(CheckPointPath))):\n",
        "       os.makedirs(CheckPointPath)\n",
        "        \n",
        "    # Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
        "    SaveCheckPoint = 100 \n",
        "    \n",
        "    # Image Input Shape\n",
        "    ImageSize = [32, 32, 3]\n",
        "    NumTrainSamples = len(TrainSet)\n",
        "\n",
        "    # Number of classes\n",
        "    NumClasses = 10\n",
        "\n",
        "    return SaveCheckPoint, ImageSize, NumTrainSamples, TrainLabels, NumClasses\n",
        "\n",
        "\n",
        "def ReadLabels(LabelsPathTrain):\n",
        "    if(not (os.path.isfile(LabelsPathTrain))):\n",
        "        print('ERROR: Train Labels do not exist in '+LabelsPathTrain)\n",
        "        sys.exit()\n",
        "    else:\n",
        "        TrainLabels = open(LabelsPathTrain, 'r')\n",
        "        TrainLabels = TrainLabels.read()\n",
        "        TrainLabels = map(float, TrainLabels.split())\n",
        "\n",
        "    return TrainLabels\n",
        "    \n",
        "\n",
        "def ReadDirNames(ReadPath):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "    ReadPath is the path of the file you want to read\n",
        "    Outputs:\n",
        "    DirNames is the data loaded from /content/data/TxtFiles/DirNames.txt which has full path to all image files without extension\n",
        "    \"\"\"\n",
        "    # Read text files\n",
        "    DirNames = open(ReadPath, 'r')\n",
        "    DirNames = DirNames.read()\n",
        "    DirNames = DirNames.split()\n",
        "    return DirNames\n",
        "\n",
        "    \n",
        "def GenerateBatch(TrainSet, TrainLabels, ImageSize, MiniBatchSize):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "    TrainSet - Variable with Subfolder paths to train files\n",
        "    NOTE that Train can be replaced by Val/Test for generating batch corresponding to validation (held-out testing in this case)/testing\n",
        "    TrainLabels - Labels corresponding to Train\n",
        "    NOTE that TrainLabels can be replaced by Val/TestLabels for generating batch corresponding to validation (held-out testing in this case)/testing\n",
        "    ImageSize is the Size of the Image\n",
        "    MiniBatchSize is the size of the MiniBatch\n",
        "   \n",
        "    Outputs:\n",
        "    I1Batch - Batch of images\n",
        "    LabelBatch - Batch of one-hot encoded labels \n",
        "    \"\"\"\n",
        "    I1Batch = []\n",
        "    LabelBatch = []\n",
        "    \n",
        "    ImageNum = 0\n",
        "    while ImageNum < MiniBatchSize:\n",
        "        # Generate random image\n",
        "        RandIdx = random.randint(0, len(TrainSet)-1)\n",
        "        \n",
        "        ImageNum += 1\n",
        "    \t\n",
        "    \t  ##########################################################\n",
        "    \t  # Add any standardization or data augmentation here!\n",
        "    \t  ##########################################################\n",
        "\n",
        "        I1, Label = TrainSet[RandIdx]\n",
        "\n",
        "        # Append All Images and Mask\n",
        "        I1Batch.append(I1)\n",
        "        LabelBatch.append(torch.tensor(Label))\n",
        "        \n",
        "    return torch.stack(I1Batch), torch.stack(LabelBatch)\n",
        "\n",
        "\n",
        "def PrettyPrint(NumEpochs, DivTrain, MiniBatchSize, NumTrainSamples, LatestFile):\n",
        "    \"\"\"\n",
        "    Prints all stats with all arguments\n",
        "    \"\"\"\n",
        "    print('Number of Epochs Training will run for ' + str(NumEpochs))\n",
        "    print('Factor of reduction in training data is ' + str(DivTrain))\n",
        "    print('Mini Batch Size ' + str(MiniBatchSize))\n",
        "    print('Number of Training Images ' + str(NumTrainSamples))\n",
        "    if LatestFile is not None:\n",
        "        print('Loading latest checkpoint with the name ' + LatestFile)              \n",
        "\n",
        "def TrainOperation(TrainLabels, NumTrainSamples, ImageSize,\n",
        "                   NumEpochs, MiniBatchSize, SaveCheckPoint, CheckPointPath,\n",
        "                   DivTrain, LatestFile, TrainSet, LogsPath):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "    TrainLabels - Labels corresponding to Train/Test\n",
        "    NumTrainSamples - length(Train)\n",
        "    ImageSize - Size of the image\n",
        "    NumEpochs - Number of passes through the Train data\n",
        "    MiniBatchSize is the size of the MiniBatch\n",
        "    SaveCheckPoint - Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
        "    CheckPointPath - Path to save checkpoints/model\n",
        "    DivTrain - Divide the data by this number for Epoch calculation, use if you have a lot of dataor for debugging code\n",
        "    LatestFile - Latest checkpointfile to continue training\n",
        "    TrainSet - The training dataset\n",
        "    LogsPath - Path to save Tensorboard Logs\n",
        "    Outputs:\n",
        "    Saves Trained network in CheckPointPath and Logs to LogsPath\n",
        "    \"\"\"\n",
        "   # Initialize the model\n",
        "    # model = CIFAR10Model(InputSize=3*32*32,OutputSize=10) \n",
        "    \n",
        "    # model = ResNet(10)\n",
        "    model = ResNeXt()\n",
        "    # model = DenseNet()\n",
        "    model = model.to(device)\n",
        "    ###############################################\n",
        "    # Fill your optimizer of choice here!\n",
        "    ###############################################\n",
        "    Optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "    # Tensorboard\n",
        "    # Create a summary to monitor loss tensor\n",
        "    Writer = SummaryWriter(LogsPath)\n",
        "\n",
        "    if LatestFile is not None:\n",
        "        CheckPoint = torch.load(CheckPointPath + LatestFile + '.ckpt')\n",
        "        # Extract only numbers from the name\n",
        "        StartEpoch = int(''.join(c for c in LatestFile.split('a')[0] if c.isdigit()))\n",
        "        model.load_state_dict(CheckPoint['model_state_dict'])\n",
        "        print('Loaded latest checkpoint with the name ' + LatestFile + '....')\n",
        "    else:\n",
        "        StartEpoch = 0\n",
        "        print('New model initialized....')\n",
        "    train = []\n",
        "    for Epochs in tqdm(range(StartEpoch, NumEpochs)):\n",
        "        NumIterationsPerEpoch = int(NumTrainSamples/MiniBatchSize/DivTrain)\n",
        "        Batches=[]\n",
        "        for PerEpochCounter in tqdm(range(NumIterationsPerEpoch)):\n",
        "            # print(\"Epoch Counter :\",PerEpochCounter)\n",
        "            Batch = GenerateBatch(TrainSet, TrainLabels, ImageSize, MiniBatchSize)\n",
        "            \n",
        "            # Predict output with forward pass\n",
        "            LossThisBatch = model.training_step(Batch)\n",
        "\n",
        "            Optimizer.zero_grad()\n",
        "            LossThisBatch.backward()\n",
        "            Optimizer.step()\n",
        "            \n",
        "            # Save checkpoint every some SaveCheckPoint's iterations\n",
        "            if PerEpochCounter % SaveCheckPoint == 0:\n",
        "                # Save the Model learnt in this epoch\n",
        "                SaveName =  CheckPointPath + str(Epochs) + 'a' + str(PerEpochCounter) + 'model.ckpt'\n",
        "                \n",
        "                torch.save({'epoch': Epochs,'model_state_dict': model.state_dict(),'optimizer_state_dict': Optimizer.state_dict(),'loss': LossThisBatch}, SaveName)\n",
        "                # print('\\n' + SaveName + ' Model Saved...')\n",
        "            Batches.append(Batch)\n",
        "            # result = model.validation_step(Batch)\n",
        "            # model.epoch_end(Epochs*NumIterationsPerEpoch + PerEpochCounter, result)\n",
        "        model.eval()\n",
        "        outputs = [model.validation_step(batch) for batch in Batches]\n",
        "        train_result = model.validation_epoch_end(outputs)\n",
        "        model.epoch_end(Epochs, train_result)\n",
        "        train.append(train_result)\n",
        "        # Tensorboard\n",
        "        Writer.add_scalar('LossEveryEpoch', train_result[\"loss\"], Epochs)\n",
        "        Writer.add_scalar('Accuracy', train_result[\"acc\"], Epochs)\n",
        "        # If you don't flush the tensorboard doesn't update until a lot of iterations!\n",
        "        Writer.flush()\n",
        "        \n",
        "\n",
        "        # Save model every epoch\n",
        "        SaveName = CheckPointPath + str(Epochs) + 'model.ckpt'\n",
        "        torch.save({'epoch': Epochs,'model_state_dict': model.state_dict(),'optimizer_state_dict': Optimizer.state_dict(),'loss': LossThisBatch}, SaveName)\n",
        "        print('\\n' + SaveName + ' Model Saved...')\n",
        "\n",
        "    return train\n",
        "def plot_losses(history):\n",
        "    losses = [x['loss'] for x in history]\n",
        "    plt.plot(losses, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Train Loss vs. No. of epochs')\n",
        "    # plt.show()  \n",
        "    plt.savefig('/home/usivaraman/CV/Cvis_HW0/Phase2/Code/Results/JAN17/ResNeXt_Loss.png')\n",
        "\n",
        "def plot_accuracies(history):\n",
        "    accuracies = [x['acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title(' Train Accuracy vs. No. of epochs')\n",
        "    # plt.show()   \n",
        "    plt.savefig('/home/usivaraman/CV/Cvis_HW0/Phase2/Code/Results/JAN17/ResNeXt_Acc.png') \n",
        "        \n",
        "\n",
        "\n",
        "# Default Hyperparameters\n",
        "NumEpochs = 50\n",
        "# transforms = tf.Compose([tf.CenterCrop(10), tf.ToTensor(),tf.RandomRotation((30,70)),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # DenseNet,ResNet (18 layer), ResNet (34 layer)\n",
        "transforms = tf.Compose([ tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # ResNext\n",
        "TrainSet = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=tf.ToTensor())\n",
        "DivTrain = 1.0\n",
        "MiniBatchSize = 256\n",
        "LoadCheckPoint = 0\n",
        "CheckPointPath = \"/content/Checkpoints/\"\n",
        "LogsPath = \"/content/Logs\"\n",
        "\n",
        "# Setup all needed parameters including file reading\n",
        "SaveCheckPoint, ImageSize, NumTrainSamples, TrainLabels, NumClasses = SetupAll(CheckPointPath)\n",
        "\n",
        "# Find Latest Checkpoint File\n",
        "if LoadCheckPoint==1:\n",
        "    LatestFile = FindLatestModel(CheckPointPath)\n",
        "else:\n",
        "    LatestFile = None\n",
        "\n",
        "# Pretty print stats\n",
        "PrettyPrint(NumEpochs, DivTrain, MiniBatchSize, NumTrainSamples, LatestFile)\n",
        "\n",
        "train = TrainOperation(TrainLabels, NumTrainSamples, ImageSize,\n",
        "                NumEpochs, MiniBatchSize, SaveCheckPoint, CheckPointPath,\n",
        "                DivTrain, LatestFile, TrainSet, LogsPath)\n",
        "    \n",
        "plot_accuracies(train)\n",
        "plot_losses(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKVVLygOJ1kd"
      },
      "source": [
        "### Test your neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY-9nSVBJ282"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "from skimage import data, exposure, img_as_float\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as tf\n",
        "from torch.optim import Adam\n",
        "from torchvision.transforms import ToTensor\n",
        "import argparse\n",
        "import shutil\n",
        "import string\n",
        "import math as m\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "\n",
        "# import PrettyTable\n",
        "import seaborn as sns\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "# Don't generate pyc codes\n",
        "sys.dont_write_bytecode = True\n",
        "\n",
        "def SetupAll():\n",
        "    \"\"\"\n",
        "    Outputs:\n",
        "    ImageSize - Size of the Image\n",
        "    \"\"\"   \n",
        "    # Image Input Shape\n",
        "    ImageSize = [32, 32, 3]\n",
        "\n",
        "    return ImageSize\n",
        "\n",
        "def StandardizeInputs(Img):\n",
        "    ##########################################################################\n",
        "    # Add any standardization or cropping/resizing if used in Training here!\n",
        "    ##########################################################################\n",
        "    return Img\n",
        "    \n",
        "def ReadImages(Img):\n",
        "    \"\"\"\n",
        "    Outputs:\n",
        "    I1Combined - I1 image after any standardization and/or cropping/resizing to ImageSize\n",
        "    I1 - Original I1 image for visualization purposes only\n",
        "    \"\"\"    \n",
        "    I1 = Img\n",
        "    \n",
        "    if(I1 is None):\n",
        "        # OpenCV returns empty list if image is not read! \n",
        "        print('ERROR: Image I1 cannot be read')\n",
        "        sys.exit()\n",
        "        \n",
        "    I1S = StandardizeInputs(np.float32(I1))\n",
        "\n",
        "    I1Combined = np.expand_dims(I1S, axis=0)\n",
        "\n",
        "    return I1Combined, I1\n",
        "                \n",
        "\n",
        "def TestOperation(ImageSize, ModelPath, TestSet, LabelsPathPred):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "    ImageSize is the size of the image\n",
        "    ModelPath - Path to load trained model from\n",
        "    TestSet - The test dataset\n",
        "    LabelsPathPred - Path to save predictions\n",
        "    Outputs:\n",
        "    Predictions written to /content/data/TxtFiles/PredOut.txt\n",
        "    \n",
        "    \"\"\"\n",
        "    # Predict output with forward pass, MiniBatchSize for Test is 1\n",
        "    model = CIFAR10Model(InputSize=3*32*32,OutputSize=10) \n",
        "    # model = DenseNet()\n",
        "    # model = ResNet(10)\n",
        "    # model = ResNeXt()\n",
        "    model = model.to(device)\n",
        "    print(model)\n",
        "    \n",
        "    CheckPoint = torch.load(ModelPath)\n",
        "    model.load_state_dict(CheckPoint['model_state_dict'])\n",
        "    \n",
        "  \n",
        "    print('Number of parameters in this model are %d ' % len(model.state_dict().items()))\n",
        "    \n",
        "    OutSaveT = open(LabelsPathPred, 'w')\n",
        "    label_set=[]\n",
        "    pred_set =[]\n",
        "    for count in tqdm(range(len(TestSet))): \n",
        "        Img, Label = TestSet[count]\n",
        "        # print(Img.shape)\n",
        "        Img, ImgOrg = ReadImages(Img)\n",
        "        # print(Img)\n",
        "       \n",
        "        Img = torch.from_numpy(Img)\n",
        "        # Img = Img.unsqueeze(0)\n",
        "        # print(Img.shape)\n",
        "        # plt.imshow(ImgOrg)\n",
        "        # Img = torch.from_numpy(Img)\n",
        "        model.eval()\n",
        "        PredT = torch.argmax(model(Img)).item()\n",
        "        label_set.append(Label)\n",
        "        pred_set.append(PredT)\n",
        "        OutSaveT.write(str(PredT)+'\\n')\n",
        "    OutSaveT.close()\n",
        "    return label_set,pred_set\n",
        "\n",
        "def Accuracy(Pred, GT):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "    Pred are the predicted labels\n",
        "    GT are the ground truth labels\n",
        "    Outputs:\n",
        "    Accuracy in percentage\n",
        "    \"\"\"\n",
        "    return (np.sum(np.array(Pred)==np.array(GT))*100.0/len(Pred))\n",
        "\n",
        "def ReadLabels(LabelsPathTest, LabelsPathPred):\n",
        "    if(not (os.path.isfile(LabelsPathTest))):\n",
        "        print('ERROR: Test Labels do not exist in '+LabelsPathTest)\n",
        "        sys.exit()\n",
        "    else:\n",
        "        LabelTest = open(LabelsPathTest, 'r')\n",
        "        LabelTest = LabelTest.read()\n",
        "        LabelTest = map(float, LabelTest.split())\n",
        "\n",
        "    if(not (os.path.isfile(LabelsPathPred))):\n",
        "        print('ERROR: Pred Labels do not exist in '+LabelsPathPred)\n",
        "        sys.exit()\n",
        "    else:\n",
        "        LabelPred = open(LabelsPathPred, 'r')\n",
        "        LabelPred = LabelPred.read()\n",
        "        LabelPred = map(float, LabelPred.split())\n",
        "        \n",
        "    return LabelTest, LabelPred\n",
        "\n",
        "def ConfusionMatrix(LabelsTrue, LabelsPred):\n",
        "    \"\"\"\n",
        "    LabelsTrue - True labels\n",
        "    LabelsPred - Predicted labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the confusion matrix using sklearn.\n",
        "    LabelsTrue, LabelsPred = list(LabelsTrue), list(LabelsPred)\n",
        "    cm = confusion_matrix(y_true=LabelsTrue,  # True class for test-set.\n",
        "                          y_pred=LabelsPred)  # Predicted class.\n",
        "\n",
        "    # Print the confusion matrix as text.\n",
        "    for i in range(10):\n",
        "        print(str(cm[i, :]) + ' ({0})'.format(i))\n",
        "\n",
        "    # Print the class-numbers for easy reference.\n",
        "    class_numbers = [\" ({0})\".format(i) for i in range(10)]\n",
        "    print(\"\".join(class_numbers))\n",
        "\n",
        "    print('Accuracy: '+ str(Accuracy(LabelsPred, LabelsTrue)), '%')\n",
        "    accuracy = Accuracy(LabelsPred, LabelsTrue)\n",
        "    return accuracy,cm\n",
        "\n",
        "\n",
        "ModelPath = \"/content/Checkpoints/0a100model.ckpt\"\n",
        "LabelsPath = \"/content/data/TxtFiles/LabelsTest.txt\"\n",
        "# transforms = tf.Compose([tf.CenterCrop(10), tf.ToTensor(),tf.RandomRotation((30,70)),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # DenseNet,ResNet (18 layer), ResNet (34 layer)\n",
        "transforms = tf.Compose([ tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # ResNext\n",
        "TestSet = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                    download=True, transform=tf.ToTensor())\n",
        "\n",
        "\n",
        "# Setup all needed parameters including file reading\n",
        "ImageSize = SetupAll()\n",
        "\n",
        "# Define PlaceHolder variables for Predicted output\n",
        "LabelsPathPred = './TxtFiles/ResNeXtPredOut.txt' # Path to save predicted labels\n",
        "\n",
        "label_set,pred_set=TestOperation(ImageSize, ModelPath, TestSet, LabelsPathPred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "LabelsTrue, LabelsPred = ReadLabels(LabelsPath, LabelsPathPred)\n",
        "Acc, CM = ConfusionMatrix(label_set, pred_set)\n",
        "sns.heatmap(CM, annot=True, fmt=\"d\")\n",
        "plt.savefig('ResNeXt.png')\n",
        "print(\"Test Accuracy = \", Acc, \"%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hw0_to_be_filled.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
